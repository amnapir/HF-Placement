---
title: "Integrating Human Factors Expertise into Development of Automated Vehicles"
subtitle: "Replication package"
author: "Amna Pir Muhammad, Alessia Knauss, Eric Knauss, Jonas BÃ¤rgman"
date: "First revision 2024-04-25. This revision `r Sys.Date()`."
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_depth: 1
bibliography: refs.bib
link-citations: true
csl: elsevier-harvard.csl
linkcolor: blue
header-includes:
  - \usepackage{amsmath}
---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(cache=TRUE)

# set this to num cores on your computer!
CORES = 4 

library(bayesplot)
library(haven)  
library(bnlearn)  
library(gRain) 
library(ggplot2)  
library(dplyr) 
library(brms)
library(tidyverse)
library(mice) 
library(mcmcplots)
library(rethinking)
library(patchwork)
library(viridis)
library(ggthemes)
theme_set(theme_tufte())

options(brms.backend="cmdstanr")
options(mc.cores = CORES) # set num cores
```

# Introduction
This document serves as a comprehensive guide to replicate the analysis conducted in our experiments. The replication package enables anyone to download, rerun the analysis, and verify our assumptions.


## Data Loading
To begin, load the dataset available in the Data/ directory of our GitHub [repository](https://github.com/amnapir/HF-Placement). The dataset is read into R using the following code:

data <- read_sav("Untitled26.sav")

In our dataset:

\item Ranking Variable: Presented by the M201_ prefix, this variable assesses preferences across ten options.
\item Effectiveness Variable: Presented by the M209_ prefix, this variable measures the effectiveness of different options.
\item Easiness Variable: Presented by the M210_ prefix, this variable evaluates the perceived ease of each option.

For more detailed information on these variables and their corresponding options, please refer to our manuscript or questionnaire.


## Convert Categorical Variables to Factors


We convert specific columns to ordered factors to ensure correct ordering in categorical analysis.

data$D104 <- factor(data$D104, levels = c("1", "2", "3"), ordered = TRUE)
data$D102 <- factor(data$D102, levels = c("1", "2", "3", "4"), ordered = TRUE)




## Data Cleaning - Handle Missing Values
We handle missing values by recoding -9 to NA for the variables starting with "M201_, "M209_", and "M210_".

modeldata <- data %>%
  mutate(across(starts_with("M201_"), ~if_else(. == -9, NA_real_, .))) %>%
  mutate(across(starts_with("M209_"), ~if_else(. == -9, NA_real_, .))) %>%
  mutate(across(starts_with("M210_"), ~if_else(. == -9, NA_real_, .))) %>%
## Create New Variables Based on Existing Ones

# Create New Variables Based on Existing Ones
We create new variables based on existing ones to simplify and categorize the data for analysis.

modeldata <- modeldata %>%
  mutate(
    D104 = D104,
    Expertise = case_when(
      D102 == 1 ~ "Human Factors",
      D102 == 2 ~ "Engineering",
      D102 == 3 ~ "Both",
      TRUE ~ "Other"
    ),
    Dev_Struc = case_when(
      I004_01 >= 1 & I004_01 <= 35 ~ "Waterfall",
      I004_01 >= 36 & I004_01 <= 70 ~ "Hybrid",
      I004_01 >= 71 & I004_01 <= 100 ~ "Agile",
      TRUE ~ "NA"
    ),
    Experience = case_when(
      D104 == 1 ~ "LevelLow",
      D104 == 2 ~ "LevelMedium",
      D104 == 3 ~ "LevelHigh",
      TRUE ~ "Other"
    ),
    AreaOfWork = case_when(
      D101_01 == 2 ~ "Supplier",
      D101_02 == 2 ~ "OEM",
      D101_03 == 2 ~ "Consultancy",
      D101_04 == 2 ~ "Research Institute",
      D101_05 == 2 ~ "University",
      D101_06 == 2 ~ "Government",
      D101_07 == 2 ~ "Non-Automotive",
      TRUE ~ "Other"
    )
  ) %>%
  pivot_longer(cols = starts_with("M209_"), names_to = "placementOption", values_to = "effectivenessRating")

## Convert Effectiveness and Easiness varaibles to Factor
We convert the "effectivenessRating" and "easinessRating" variables to an ordered factor for correct ordering in the Bayesian analysis.

modeldata$effectivenessRating <- factor(modeldata$effectivenessRating, levels = c("1", "2", "3", "4", "5"), ordered = TRUE)
modeldata$easinessRating <- factor(modeldata$easinessRating, levels = c("1", "2", "3", "4", "5"), ordered = TRUE)

## Define Bayesian Formula
We define the Bayesian formula to predict "Effectiveness" based on various predictors.

model_formula <- bf(effectivenessRating ~ placementOption + Experience + Expertise + AreaOfWork + Dev_Struc + (1|ID))

## Prior Specification
We specify the prior distributions for the Bayesian model parameters.

prior_spec <- c(
  prior(normal(0, 5), "b"),
  prior(normal(0, 10), "Intercept"),
  prior(cauchy(0, 2), "sd")
)


## Prior Predictive Checks
We check the and plot the priors from the sample only without empirical data. Sample only from the priors.
Evidently the medians are quite evenly set along the $x$-axis, and the uncertainty is fairly uniformly distributed among the categories $1,\ldots,6$ (the bars).


fit <- brm(
  formula = model_formula,
  data = modeldata,
  family = cumulative(probit), 
  prior = prior_spec,
  chains = 4,
  sample_prior = "only",
  cores = 4,
 seed = 12345
)
pp_check(fit, type = "bars", nsamples = 250)

## Bayesian Model Fitting
We fit the Bayesian model to the data using the specified formula, priors, and settings.

## Sample with data
fit <- brm(
  formula = model_formula,
  data = modeldata,
  family = cumulative(probit),
  prior = prior_spec,
  chains = 4,
  cores = 4,
  seed = 12345
)
```
## Summary and Diagnostics
We print the summary of the fitted model and perform diagnostic checks to ensure the model has converged and is reliable.
Our caterpillar plots look good for all estimated parameters (i.e., they look like fat caterpillars when the chains have mixed well).

mcmc_trace(fit, regex_pars = "^b_") + legend_none()

Diagnostics such as divergences, tree depth, energy, $\widehat{R}$, and $\mathrm{ESS}$ all look good.

rstan::check_hmc_diagnostics(eval(fit)$fit)

## Posterior Predictive Checks
We perform posterior predictive checks to assess how well the model fits the data.
```
pp_check(fit, type = "bars", nsamples = 250)

## Extract and Plot Posterior Distributions
We extract posterior samples and plot the posterior distributions for the model coefficients.


posterior_samples <- posterior_samples(fit)
coefficients <- grep("b_", colnames(posterior_samples), value = TRUE)

plots <- lapply(coefficients, function(coef_name) {
  ggplot(posterior_samples, aes_string(x = coef_name)) +
    geom_density(fill = "blue", alpha = 0.5) +
    labs(title = paste("Posterior Distribution for", gsub("b_", "", coef_name)),
         x = "Effect Size", y = "Density")
})

